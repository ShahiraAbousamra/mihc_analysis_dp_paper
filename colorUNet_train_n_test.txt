1. Use src_read_data_labels\extract_patches_shahira_reg.py to extract patches and generate superpixel labels.
 
	Need to modify: paths, stains values and counts, how source data points are read, downsampling, patch size. 

3. Make a copy of the training configuration file:
	NNFramework_PyTorch/config_multiplex_seg_train/config_multiplex_seg_unet_dots_retrain.ini

and modify the following variables (tunable variables):

	model_path: the output path. Make sure this path exists.

	model_base_filename: prefix name used in output files

	model_restore_filename: if continuing training set path to previous checkpoint, otherwise comment out

	n_stains: number of stains (including background)

	input_img_height, input_img_width: image width and height that the input patch will be scaled to (modify in train and validate config). 

	pad_y, pad_x: padding required so that output is same size as input (modify in train and validate config). 

	filepath_data = filepath_label = location of training/validation data.

	max_epochs: number of training epochs

	batch_size: batch size per iteration. ( Decrease if get cuda out of memory error).
	
	learning_rate: optimizer learning rate
	
	class_weights: comma separated relative weight given to each stain class. In pytorch implementation, the weights are normalized (divided by their sum).

	
3. Run the training:
cd NNFramework_Pytorch_external_call

CUDA_VISIBLE_DEVICES='7' nohup  python ./external_seg.py <config file path> 0 &

Tip: The output log files from training show the training and validation losses every epoch. 
While training, if the model starts to diverge (i.e. training loss increase), stop the training and reduce the learning rate or use the epoch just before that (with the lowest training loss).
Trained model avg training loss = 0.043924, avg validation loss = 5.716491

4. For test, make a copy of the test configuration file:
	NNFramework_PyTorch/config_multiplex_seg_test/config_multiplex_seg_unet_dots_retrain_e410_test_19patches.ini

and modify the variables in the sections: [DEFAULT] and [NETWORK] as in training, in addition to:
 [TEST_DATA] pad_y, pad_x:
 
 [TESTER] out_dir: make sure this directory exists

run similar to step 3.

6. To generate argmax segmentation:
use the file seg_argmax_sup.py
modify the thresh_dict (concentration threshold) and the size_thresh_dict (size threshold)
In the file main, set the input and  output paths

7. To visualize segmentations:
use the file vis_seg.py
In the file main, set the input and  output paths

